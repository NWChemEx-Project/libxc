# LibXC for GPU

We want to have LibXC run on GPUs so that all the DFT related work can be kept
on the device and communication can be avoided. In our approach we use CUDA
because that gives us the most control. For the inputs the density and its
derivatives are evaluated on the GPU. In addition the derivatives of the
functional are consumed on the GPU as well. 

LibXC manages the details of the functional in an intricate way. Dealing with
this on the GPU would cause a number of issues. Therefore we do not want to
deal with this on the device. Instead we propose to handle the logic of 
the functional entirely on the host. Just when we get to actually evaluating
the functional we want to launch a kernel on the GPU to do this.

Implementing the above approach requires a number of steps.

## Extending xc_func_info_type

xc_func_info_type holds a variety of data about the functional. This information
includes function pointers to the code that evaluates the functional. In the
original version of LibXC those pointers are called `lda`, `gga`, and `mgga`
for function pointers with a corresponding API. 

For the GPU implementation `lda`, `gga`, and `mgga` will remain the same 
except that they will now point to `__host__` versions of the functional code.
To deal with the device code we add `lda_offload`, `gga_offload`, and
`mgga_offload` that point to `__global__` functions that invoke the device
implementations of the functional. 

## Extending the functional implementations

The code for the functionals is generated by extensively using function 
inlining. The function is provided by Maple generated code which is included
into a file that captures all the important functional material. The
functional is inlined into a `work_<functionalType>` routine (e.g. 
`work_lda`). Pointers to this code are stored in a `xc_func_info_type`
data structure.

For the GPU implementation the `work_lda` function will be declared as 
`__host__ __device__` to generate CPU and GPU versions of this code. A pointer
to the CPU code will be stored in `xc_func_info_type` just like with the 
original code. However we cannot do the same for the GPU code. Instead we
need to add a `__host__ work_lda_offload` function that will launch the 
device code on the GPU through a call to `__global__ work_lda_device`.
The pointer to this offload function will be stored
in `xc_func_info_type`. 

## Dealing with xc_func_type

The function `xc_func_init` sets the definition of the functional up 
dependent on the number ID of the functional requested. The data is stored 
in an `xc_func_type` data structure. The problem with this approach is that
sending parameters for the functional over to the GPU for every kernel 
invocation is likely prohibitively expensive. Duplicating the `xc_func_type`
on the device is also problematice because it stores the functional 
definition as a tree of multiple functional terms. Also the original 
`xc_func_type` data structure contained several pointers to other
data structures. This means that copying this data structure over to the
device requires rebuilding the whole pointer structure on the device as 
well.

The approach taken here was to remove most of the pointers from 
`xc_func_type` by replacing them with fixed size arrays. This
makes that `xc_func_type` contains all information needed on the device
without any pointers. Then we build an array of `xc_func_type` with
an entry for every functional. A new function `xc_func_init_all` 
initializes all functionals (`xc_func_end_all` finalizes all functionals).
This function also creates a full table of all functional definitions on
the device.

For the GPU implementation we can make use of the fact that the functional is
fixed when `xc_func_init` completes. As we know that the functional is 
evaluated by a depth-first traversing of the tree we can flatten the tree
into an array. This array can be send to the device in an small extension
of the `xc_func_init` function. When we traverse the tree to evaluate the
functional we just need to pass the number of the term to the device with
every kernel invocation to pick the correct parameters.

One of the things we need to do this is a function that take the functional
identifier and returns the corresponding rank of the identifier in 
`xc_functional_keys`, and we need to store this rank in `xc_func_type`
for easy retrieval (finding the rank during the functional evaluation is 
likely to be very costly).

## Building the code for the GPU

Building LibXC for the GPU has a number of challenges. First of all
LibXC has GPU code spread over multiple files. To compile this correctly
you need to generate relocatable device code. This requires special 
compiler flags, one of the following two options will do the trick:
```
   -rdc true
   --relocatable-device-code true
```
Unfortunately CMake does not handle this very well. CMake knows about this
concept as SEPARABLE_COMPILATION, but I have had plenty of trouble to get
that to add the proper compiler flags. In practice I have to hand edit
`CMakeCache.txt` to add `-rdc true` to `CMAKE_CUDA_FLAGS`.

Another issue is that GPUs are very limited on the number of registers they
have available. Compiling GPU code with the default settings is likely to
produce code that will fail to launch on the device because there are not
enough resources. Therefore it is adviced to also add 
```
   --maxrregcount 64 --use_fast_math -gencode arch=compute_70,code=sm_70
```
to `CMAKE_CUDA_FLAGS`.
